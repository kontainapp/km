#
# Copyright 2021 Kontain Inc
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#
name: KM CI Pipeline
on:
  pull_request:
    branches: [master]
    paths-ignore:
      # See https://docs.github.com/en/actions/reference/workflow-syntax-for-github-actions#filter-pattern-cheat-sheet
      - "**.md" # all .md files in repo
      - "**/docs/**" # all content of all docs/ dirs in repo
      - compile_commands.json
      - .vscode/**
      - km-releases
      - payloads/longhaul-test/**
      - "**/L0-image**"
  push:
    branches: [master]
    paths-ignore:
      - "**.md" # all .md files in repo
      - "**/docs/**" # all content of all docs/ dirs in repo
      - compile_commands.json
      - .vscode/**
      - km-releases
      - payloads/longhaul-test/**
      - "**/L0-image**"

  schedule:
    # Posix cron format:
    # https://pubs.opengroup.org/onlinepubs/9699919799/utilities/crontab.html#tag_20_25_07
    # Minute Hour DayOfMonth MonthOfYear DayOfWeek
    - cron: "0 7 * * *" # Daily build midnight pacific time (UTC + 7)
    # Gitgub doc says:
    #    Scheduled workflows run on the latest commit on the default or base branch.
    #    The shortest interval you can run scheduled workflows is once every 5 minutes.

  # Manual trigger.
  # See https://github.blog/changelog/2020-07-06-github-actions-manual-triggers-with-workflow_dispatch/
  workflow_dispatch:
    inputs:
      run_type:
        description: "Run type: regular or nightly"
        default: "regular"
        required: true

env:
  BUILDENV_IMAGE_VERSION: latest # use this for all buildenv containers
  IMAGE_VERSION: ci-${{ github.run_number }} # use this for all other containers
  NIGHTLY_CLUSTER_NAME: "aks-kontain-nightly-ci-${{ github.run_number }}"
  SP_SUBSCRIPTION_ID: ${{ secrets.SP_SUBSCRIPTION_ID }}
  SP_APPID: ${{ secrets.SP_APPID }}
  SP_PASSWORD: ${{ secrets.SP_PASSWORD }}
  SP_TENANT: ${{ secrets.SP_TENANT }}
  # TRACE: true # uncomment to enable '-x' in all bash scripts

jobs:
  # starts self-hosted runner in AWS and Azure. They are NOT ephemeral and will run until cleanup in the stop-runner
  # start-runners:
  #   name: Start cloud runners
  #   runs-on: ubuntu-latest
  #   outputs:
  #     run-ons: ${{ steps.start-cloud-runner.outputs.run-ons }}
  #   steps:
  #     - name: Get public Keys
  #       uses: actions/checkout@v2

  #     - name: Start Cloud runners
  #       id: start-cloud-runner
  #       uses: kontainapp/cloud-github-runner@v3.1
  #       with:
  #         mode: start
  #         github-token: ${{ secrets.GH_TOKEN }}
  #         runner-user: kontain
  #         subnet: "10.0.0.0"
  #         public-keys-dir: ${{ github.workspace }}/cloud/ssh
  #         ec2-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
  #         ec2-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
  #         ec2-region: "us-east-2"
  #         ec2-image: "L0BaseAWSImage"
  #         ec2-instance-type: "m5.xlarge"
  #         ec2-vpc-name: "github-runner"
  #         az-subscription-id: ${{ secrets.SP_SUBSCRIPTION_ID }}
  #         az-client-id: ${{ secrets.SP_APPID }}
  #         az-secret: ${{ secrets.SP_PASSWORD }}
  #         az-tenant-id: ${{ secrets.SP_TENANT }}
  #         az-image: "auto-github-runner:L0BaseImage"
  #         az-location: "westus"
  #         az-vm-size: "Standard_D4s_v4"

  km-build:
    name: Build KM, push test image
    runs-on: ubuntu-20.04
    steps:
      - uses: actions/checkout@v2
        with:
          submodules: true

      - name: Print build environment info
        run: |
          echo "Event: ${{ github.event_name }} inputs.run_type: ${{ github.event.inputs.run_type }}"
          echo ====Environment info===
          echo "SHA: $(git rev-parse HEAD)"
          echo "=== Last 10 commits:"
          git log -n 10 --graph --pretty=format:'%h% %d %s %cr %ce'
          echo "=== VM/OS:"
          cat /proc/version
          cat /etc/os-release
          echo "=== Docker version:"
          docker version
          echo ==== Environment Variables
          env
          echo ==== CPU Info
          lscpu

      - run: make -C cloud/azure login-cli

      - name: Prepare KM build env
        run: make -C tests pull-buildenv-image .buildenv-local-lib

      - name: Build KM and tests using buildenv image
        run: make -j withdocker RUN_IN_CI=1

      - name: Build KM for coverage
        run: make -C km -j withdocker TARGET=coverage
        if: env.TEST_COVERAGE == 'true'

      # - name: Build and push KM testenv image
      #   run: make -C tests testenv-image push-testenv-image

      # - name: Build payloads and create test images
      #   run: |
      #     make -C payloads -j pull-buildenv-image
      #     make -C payloads -j clean
      #     make -C payloads -j all
      #     make -C payloads -j testenv-image
      #     make -C payloads -j push-testenv-image

      # - name: Create payloads runenv and demo-runenv images
      #   # Note: this builds both runenv and demo-runenv images
      #   run: |
      #     make -C payloads -j runenv-image
      #     make -C payloads -j push-demo-runenv-image

      # Note: custom Python build needs to happen after python payload build
      # - name: Python.km custom build
      #   run: |
      #     make -C payloads/python build-modules pack-modules CUSTOM_MODULES="markupsafe wrapt"
      #     make -C payloads/python custom CUSTOM_MODULES="markupsafe wrapt"

      # - name: Build faktory
      #   run: make -C tools/faktory all

      - name: Build shim
        run: |
          make -C cloud/k8s/deploy/shim
          mkdir /opt/kontain/bin/shim
          cp -r build/cloud/k8s/deploy/shim/* /opt/kontain/bin/shim

      - uses: actions/upload-artifact@v2
        with:
          name: km
          path: |
            /opt/kontain/bin/km
            /opt/kontain/bin/krun
            /opt/kontain/bin/shim
          retention-days: 7

      - uses: actions/upload-artifact@v2
        with:
          name: km-build
          path: |
            build/cloud/k8s/deploy/shim
            build/km/km
            tests/hello_test.km

          retention-days: 7

  # Builds a static linked, stripped binary for krun/crun
  # This uses the NIX virtual machine, just like the crun CI.
  # NIX takes a long time, so we build the static krun binary in
  # parallel with the rest of KM build and test.
  krun-static-build:
    name: Build static KRUN binary
    runs-on: ubuntu-20.04
    steps:
      - uses: actions/checkout@v2
        with:
          submodules: recursive
      - name: Set env
        run: echo "CRUN_SHA=$(cd container-runtime/crun/ && git rev-parse --short=12 HEAD)" >> $GITHUB_ENV

      # get persistent artifact that contains static krun
      # it will set step's output variable artifact-status to either 'available' or 'not-found'
      # Note: to figure out where krun needs to be rebuild ot not we use SHA of the container-runtime/crun/ directory
      # in teh step above. That SHA becomes artifact name. If there were changes to krun, SHA will change
      # forcing the re-build
      - name: check artifact
        id: check-artifact
        uses: kontainapp/persistent-artifact@v1
        with:
          github-token: ${{ secrets.GH_TOKEN }}
          artifact-name: ${{ env.CRUN_SHA}}
          path: /tmp/krun-static
          debug: true

      # if persistent artifact was not found, i.e output of the previous step artifact-status != 'available'
      # build krun
      - uses: actions/cache@v2
        if: ${{ steps.check-artifact.outputs.artifact-status != 'available' }}
        with:
          path: .cache
          key: nix-v1-${{ hashFiles('container-runtime/crun/nix/nixpkgs.json') }}

      - name: Build krun
        if: ${{ steps.check-artifact.outputs.artifact-status != 'available' }}
        run: |
          set -x
          CRUN_DIR=$(pwd)/container-runtime/crun
          # These next two lines were taken from the crun release.yaml and build-aux/release.sh
          # to setup and execute a nix based build of stripped static
          if [[ -z $(ls -A /nix) ]]; then sudo docker run --rm --privileged -v /:/mnt nixos/nix:2.3.12 cp -rfT /nix /mnt/nix; fi
          sudo docker run --rm --privileged -v /nix:/nix -v ${CRUN_DIR}:${CRUN_DIR} -w ${CRUN_DIR} nixos/nix:2.3.12 nix build --print-build-logs --file nix/
          mkdir -p /tmp/krun-static
          cp ${CRUN_DIR}/result/bin/crun /tmp/krun-static/krun.static

      # if persistent artifact was not found, i.e output of the previous step artifact-status != 'available'
      # and was built in the previous step, upload it with SHA as artifact name
      - uses: actions/upload-artifact@v2
        if: ${{ steps.check-artifact.outputs.artifact-status != 'available' }}
        with:
          name: ${{ env.CRUN_SHA}}
          path: /tmp/krun-static

      # regardles how we got krun-static (by retrieving persistent artifact or bulding)
      # upload it as krun-static artifact
      - uses: actions/upload-artifact@v2
        with:
          name: krun-static
          path: /tmp/krun-static/krun.static

  # Build the k8s release artifact. Static KRUN is built separately and
  # in parallel from the rest of KM. The k8s artifact contains:
  #  km - km executable
  #  containerd-shim-krun-v2 - containerd shim for krun
  #  krun - krun executable
  k8s-release-bin:
    name: make k8s release bundle
    runs-on: ubuntu-20.04
    needs: [km-build, krun-static-build]
    steps:
      - uses: actions/checkout@v2
        with:
          submodules: true

      # get build directory created by km-build job
      - uses: actions/download-artifact@v2
        with:
          name: km-build
          path: .

      #get static krun created by krun-static-build job
      - uses: actions/download-artifact@v2
        with:
          name: krun-static
          path: build/container-runtime

      - name: rename rkun.static to krun
        run: |
          set -x
          # rename rkun.static to krun
          mv build/container-runtime/krun.static build/container-runtime/krun

      - name: Checking download and creating build directory
        run: |
          ls -R build
          ls -R tests

      - run: make -C cloud/azure login-cli

      - name: Prepare KM build env
        run: make -C tests pull-buildenv-image .buildenv-local-lib

      - name: Create kkm release artifact
        run: make withdocker TARGET=kkm-pkg

      # Note: need to have kkm.run ready for this step
      - name: Create kontain bundles
        run: make withdocker TARGET=release

      - uses: actions/upload-artifact@v2
        with:
          name: km-k8s-rel-artifact
          path: ./build/kontain_bin.tar.gz

  # km-test:
  #   name: KM, payloads, krun tests, KVM on Azure
  #   runs-on: ${{ fromJSON(needs.start-runners.outputs.run-ons)['azure'] }}
  #   needs: [start-runners, km-build]
  #   steps:
  #     - uses: actions/checkout@v2
  #       with:
  #         submodules: true

  #     - run: make -C cloud/azure login-cli

  #     - uses: actions/download-artifact@v2
  #       with:
  #         name: km
  #         path: /tmp/

  #     - name: Configure KRUN
  #       run: |
  #         sudo mkdir -p /opt/kontain/bin
  #         sudo mv -t /opt/kontain/bin /tmp/km /tmp/krun
  #         sudo chmod +x /opt/kontain/bin/km /opt/kontain/bin/krun
  #         sudo bash ./container-runtime/podman_config.sh
  #         sudo bash ./container-runtime/docker_config.sh
  #         echo 'KERNEL=="kvm", GROUP="kvm", MODE="0666"' > /tmp/rules
  #         sudo mv /tmp/rules /etc/udev/rules.d/99-perm.rules
  #         sudo udevadm control --reload-rules && sudo udevadm trigger

  #     - name: Pull testenv images
  #       run: |
  #         make -C tests pull-testenv-image
  #         make -C payloads -j pull-testenv-image

  #     - name: KM with KVM Test - Azure
  #       run: make -C tests test-withdocker DOCKER_INTERACTIVE=
  #       timeout-minutes: 20

  #     - name: KM with KVM Payloads Test - Azure
  #       if: ${{ ! (github.event_name == 'schedule' ||
  #         (github.event_name == 'workflow_dispatch' && github.event.inputs.run_type == 'nightly')) }}
  #       run: make -C payloads test-withdocker DOCKER_INTERACTIVE=
  #       timeout-minutes: 20

  #     - name: KM with KVM Payloads Test - Azure
  #       if: ${{ github.event_name == 'schedule' ||
  #         (github.event_name == 'workflow_dispatch' && github.event.inputs.run_type == 'nightly') }}
  #       run: make -C payloads test-all-withdocker DOCKER_INTERACTIVE=
  #       timeout-minutes: 20

  #     - name: KM with KVM Validate runenv images - Azure
  #       run: |
  #         make -C payloads/ -j pull-demo-runenv-image
  #         make -C payloads validate-runenv-image DOCKER_INTERACTIVE=
  #       timeout-minutes: 20

  kkm-build:
    name: Build KKM, save test artifacts
    runs-on: ubuntu-20.04
    steps:
      - uses: actions/checkout@v2
        with:
          submodules: true

      - name: Build KKM and KKM tests
        run: make -C kkm/kkm && make -C kkm/test_kkm

      - name: Install KKM
        run: sudo insmod kkm/kkm/kkm.ko

      - name: Sanity check - unit test
        run: ./kkm/test_kkm/test_kkm

      - uses: actions/upload-artifact@v2
        with:
          name: kkm
          path: |
            kkm/kkm/kkm.ko
            kkm/test_kkm/test_kkm
          retention-days: 7

  # # TODO: Maybe not needed - review
  # kkm-test:
  #   name: KM tests, KKM on CI VM
  #   runs-on: ubuntu-20.04
  #   needs: [km-build, kkm-build]
  #   steps:
  #     - uses: actions/checkout@v2
  #       with:
  #         submodules: true
  #     - run: make -C cloud/azure login-cli

  #     - uses: actions/download-artifact@v2
  #       with:
  #         name: kkm
  #         path: kkm
  #     - run: chmod a+x kkm/test_kkm/test_kkm

  #     - name: Install KKM
  #       run: sudo insmod kkm/kkm/kkm.ko

  #     - name: Pull testenv image
  #       run: make -C tests pull-testenv-image

  #     - name: KM Tests - locally with KKM
  #       run: make -C tests test-withdocker HYPERVISOR_DEVICE=/dev/kkm DOCKER_INTERACTIVE=
  #       timeout-minutes: 15

  #     - name: Get kernel logs
  #       if: always()
  #       run: sudo dmesg

  # kkm-test-vms:
  #   name: KM tests, KKM AWS
  #   needs: [start-runners, km-build, kkm-build]
  #   runs-on: ${{ fromJSON(needs.start-runners.outputs.run-ons)['ec2'] }}
  #   steps:
  #     - uses: actions/checkout@v2
  #       with:
  #         submodules: true

  #     - run: make -C cloud/azure login-cli

  #     - uses: actions/download-artifact@v2
  #       with:
  #         name: km
  #         path: /tmp/

  #     - name: KKM and KKM tests
  #       run: |
  #         make -C kkm/kkm && make -C kkm/test_kkm
  #         sudo insmod kkm/kkm/kkm.ko
  #         ./kkm/test_kkm/test_kkm
  #         sudo mkdir -p /opt/kontain/bin
  #         sudo mv -t /opt/kontain/bin /tmp/km /tmp/krun
  #         sudo chmod +x /opt/kontain/bin/km /opt/kontain/bin/krun
  #         sudo bash ./container-runtime/podman_config.sh
  #         sudo bash ./container-runtime/docker_config.sh

  #     - name: Pull testenv images
  #       run: |
  #         make -C tests pull-testenv-image
  #         make -C payloads -j pull-testenv-image

  #     - name: KM with KKM Test - AWS
  #       run: make -C tests test-withdocker HYPERVISOR_DEVICE=/dev/kkm DOCKER_INTERACTIVE=
  #       timeout-minutes: 20

  #     - name: KM with KKM Payloads Test - AWS
  #       if: ${{ ! (github.event_name == 'schedule' ||
  #         (github.event_name == 'workflow_dispatch' && github.event.inputs.run_type == 'nightly')) }}
  #       run: make -C payloads test-withdocker HYPERVISOR_DEVICE=/dev/kkm DOCKER_INTERACTIVE=
  #       timeout-minutes: 20

  #     - name: KM with KKM Payloads Test - AWS (nightly)
  #       if: ${{ github.event_name == 'schedule' ||
  #         (github.event_name == 'workflow_dispatch' && github.event.inputs.run_type == 'nightly') }}
  #       run: make -C payloads test-all-withdocker HYPERVISOR_DEVICE=/dev/kkm DOCKER_INTERACTIVE=
  #       timeout-minutes: 20

  #     - name: KM with KKM Validate runenv images - AWS
  #       run: |
  #         make -C payloads/ -j pull-demo-runenv-image
  #         make -C payloads validate-runenv-image HYPERVISOR_DEVICE=/dev/kkm DOCKER_INTERACTIVE=
  #       timeout-minutes: 20

  minikube-testing:
    name: kubernetes tests against minikube
    runs-on: ubuntu-20.04
    needs: [k8s-release-bin, kkm-build]
    strategy:
      matrix:
        # We want to test against containerd and crio. crio support is a bit brittle in
        # minikube. In our experience (late 2021) it works better with the podman minikube
        # driver than the docker minikube driver.
        runtime: ["containerd"] # "cri-o" later
        driver: ["docker", "podman"]
    steps:
      - uses: actions/checkout@v2
        with:
          submodules: true

      - uses: actions/download-artifact@v2
        with:
          name: kkm
          path: kkm
      - run: chmod a+x kkm/test_kkm/test_kkm

      - uses: actions/download-artifact@v2
        with:
          name: km-k8s-rel-artifact
          path: /tmp/bin_release

      - name: Check that krun is in fact static (EZ - for verification only)
        run: ldd /tmp/bin_release/container-runtime/krun

      - name: print downloaded artifact
        run: find /tmp/bin_release

      - name: start local file server
        run: |
          (cd /tmp/bin_release; python3 -m http.server 8000) &

      - name: Install KKM
        run: sudo insmod kkm/kkm/kkm.ko

      - name: Start minikube
        run: |
          minikube version
          minikube start --container-runtime=${{ matrix.runtime }} --driver=${{ matrix.driver }} --wait=all || minikube logs

      - name: Install Kontain on minikube k8s
        run: |
          # merges and applies all the files for CI overlay
          kubectl apply -k cloud/k8s/deploy/kontain-deploy/overlays/ci
          # kubectl apply -f cloud/k8s/deploy/runtime-class.yaml
          # kubectl apply -f cloud/k8s/deploy/cm-install-lib.yaml
          # kubectl apply -f cloud/k8s/deploy/cm-containerd-install.yaml
          # kubectl apply -k cloud/k8s/deploy/kontain-deploy/ci
          sleep 20

      # uncomment to get logs from damonset.
      #- name: Check k8s install
      #  run: |
      #    set -x
      #    kubectl get pod -A
      #    kubectl logs -n kube-system -l app=kontain-init

      - name: Run user test
        run: |
          # start the test pod, which will just sleep
          kubectl apply -f demo/k8s/test.yaml
          sleep 10
          # exec `uname -r` on the test pod. Should get back '.kontain.KKM' appended to the linux release name
          pname=$(kubectl get pod -l kontain=test-app -o jsonpath="{.items[0].metadata.name}")
          rname=$(kubectl exec "${pname}" -- uname -r)
          echo "uname -r returned ${rname}"
          echo "${rname}" | grep -q -e '.*\.kontain\.KKM$' || exit 1
          echo "Kontain Runtime OK".

  ecs-hack-test:
    name: test alternate KM triggers
    runs-on: ubuntu-20.04
    needs: [k8s-release-bin, kkm-build]
    steps:
      - uses: actions/checkout@v2
        with:
          submodules: true

      - uses: actions/download-artifact@v2
        with:
          name: kkm
          path: kkm
      - run: chmod a+x kkm/test_kkm/test_kkm

      - uses: actions/download-artifact@v2
        with:
          name: km-k8s-rel-artifact
          path: /tmp/bin_release

      - name: Install KKM
        run: sudo insmod kkm/kkm/kkm.ko

      - name: Untar release
        run: tar -C /tmp/bin_release -xf /tmp/bin_release/km-k8s-release-artifact.tar.gz

      - name: Stop Docker
        run: sudo systemctl stop docker

      - name: Install KM and Reconfigure Docker
        run: |
          sudo mkdir -p /opt/kontain/bin
          sudo cp /tmp/bin_release/km/km /opt/kontain/bin/km
          sudo cp /tmp/bin_release/container-runtime/krun /opt/kontain/bin/krun-label-trigger
          sudo cp /tmp/bin_release/cloud/k8s/deploy/shim/containerd-shim-krun-v2 /usr/bin/containerd-shim-krun-v2
          cat << EOF | sudo tee /etc/docker/daemon.json
             {
                 "default-runtime": "krun",
                 "runtimes": {
                     "krun": {
                         "path": "/opt/kontain/bin/krun-label-trigger"
                     }
                 }
             }
          EOF

      - name: restart Docker
        run: |
          sudo systemctl daemon-reload
          sudo systemctl restart docker

      - name: Check krun personality
        run: |
          OUT=$(docker run --rm -v /.kontain busybox uname -r)
          echo ${OUT} | grep -q '.*\.kontain.KKM$'

      - name: Check crun personality
        run: |
          OUT=$(docker run --rm busybox uname -r)
          echo ${OUT} | grep -v -q '.*\.kontain.KKM$'

  # codeql-scan:
  #   # CodeQL Code Scanning/Static Analysis
  #   name: Analyze
  #   runs-on: ubuntu-latest
  #   permissions:
  #     actions: read
  #     contents: read
  #     security-events: write

  #   container:
  #     image: kontainapp/buildenv-km-fedora:latest

  #   strategy:
  #     fail-fast: false
  #     matrix:
  #       language: ["cpp"]

  #   steps:
  #     - name: Checkout repository
  #       uses: actions/checkout@v2

  #     # Initializes the CodeQL tools for scanning.
  #     - name: Initialize CodeQL
  #       uses: github/codeql-action/init@v1
  #       with:
  #         languages: ${{ matrix.language }}
  #         # enhanced security checks.
  #         queries: security-extended

  #     - run: |
  #         make -C km all

  #     - name: Perform CodeQL Analysis
  #       uses: github/codeql-action/analyze@v1

  # slack-workflow-status:
  #   name: Notify slack, if needed
  #   runs-on: ubuntu-latest
  #   # 'contains' shows how to add conditions, e.g. on workflow 'name:', or many other contexts.
  #   # see https://docs.github.com/en/actions/reference/context-and-expression-syntax-for-github-actions
  #   if: (failure() && github.ref == 'refs/heads/master') ||
  #     contains(github.workflow, 'noisy')
  #   # Dependencies. (A skipped dependency is considered satisfied)
  #   needs:
  #     [
  #       km-build,
  #       krun-static-build,
  #       kkm-build,
  #       km-test,
  #       kkm-test,
  #       kkm-test-vms,
  #       minikube-testing,
  #       codeql-scan,
  #       ecs-hack-test,
  #     ]
  #   steps:
  #     - name: Send notification to slack
  #       uses: Gamesight/slack-workflow-status@master
  #       with:
  #         repo_token: ${{ secrets.GITHUB_TOKEN }}
  #         slack_webhook_url: ${{ secrets.SLACK_WEBHOOK_URL }}
  #         include_jobs: true
  #         channel: "#build_and_test"
  #         name: "CI workflow status"
  #         icon_emoji: ":thumbsdown:"

  # # This step is to clean up on-demand runner. They work in conjunction with start-runner.
  # # Make sure to add dependencies in both "needs" clauses
  # stop-runner:
  #   if: always()
  #   name: Terminate self-hosted cloud runners
  #   needs: [start-runners, km-test, kkm-test-vms]
  #   runs-on: ubuntu-latest
  #   steps:
  #     - name: Stop runners
  #       uses: kontainapp/cloud-github-runner@v3.1
  #       with:
  #         mode: stop
  #         status: ${{ toJSON(needs) }}
  #         github-token: ${{ secrets.GH_TOKEN }}
  #         ec2-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
  #         ec2-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
  #         ec2-region: "us-east-2"
  #         az-subscription-id: ${{ secrets.SP_SUBSCRIPTION_ID }}
  #         az-client-id: ${{ secrets.SP_APPID }}
  #         az-secret: ${{ secrets.SP_PASSWORD }}
  #         az-tenant-id: ${{ secrets.SP_TENANT }}
